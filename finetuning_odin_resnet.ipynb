{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theostoican/Guided-Research/blob/main/finetuning_odin_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54dZ-iFaU_32"
      },
      "source": [
        "# Extract pretrained ResNet on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56f577905d3344589cc33ff9be673bf8",
            "7b7c07e61dc14a33a9a627c6032b4f1f",
            "c7c575f7a25e4c64a87457b1f4c7c91d",
            "f586e5a2277b4e3498290f83cb993a7f",
            "bc453cbeee774494aeb4db37a760351e",
            "32e751e59fc5478e883ccadf01347031",
            "0a86c7861db4449980fd1779593ad4a6",
            "dcd7b79344a444d7995d665f63f506a5",
            "b6499f411fc847b6966bda351a4281f5",
            "a0b9d4f167a04795ae09706add1080b2",
            "7169c9b31a84472aa33fe8a936d3216a"
          ]
        },
        "id": "e_wKiCG13xmA",
        "outputId": "234f4535-c2cd-4bd8-bf70-0e9006f4b4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 86.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56f577905d3344589cc33ff9be673bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms as pth_transforms\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "!pip install timm\n",
        "!pip install torchvision\n",
        "import timm\n",
        "import requests\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCsHem_qor5-",
        "outputId": "02b62047-88b5-49f6-c2f6-a25aa628069c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "# summary(vitb16, (1, 3, 224, 224))\n",
        "\n",
        "image_size = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUdTau3SIG2f"
      },
      "source": [
        "# MLP for predictor and projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnVxU-hzVciT"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# MLP class for projector and predictor\n",
        "\n",
        "def MLP(dim=512, projection_size=256, hidden_size=4096):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(dim, hidden_size),\n",
        "        nn.BatchNorm1d(hidden_size),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(hidden_size, projection_size)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_XDNM9PIJ2t"
      },
      "source": [
        "# The whole Odin architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxzMMnZu5AW0"
      },
      "source": [
        "## Various helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW9jtt1G4_IS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "def set_requires_grad(model, val):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = val\n",
        "\n",
        "class EMA():\n",
        "    def __init__(self, beta):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def update_average(self, old, new):\n",
        "        if old is None:\n",
        "            return new\n",
        "        return old * self.beta + (1 - self.beta) * new\n",
        "\n",
        "def update_moving_average(ema_updater, ma_model, current_model):\n",
        "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
        "        old_weight, up_weight = ma_params.data, current_params.data\n",
        "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
        "\n",
        "class RandomApply(torch.nn.Module):\n",
        "    def __init__(self, fn, p):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.p = p\n",
        "    def forward(self, x):\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "        return self.fn(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Cbm0uw5HYh"
      },
      "source": [
        "## Wrapper class for the thata, tau, and csi encoders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3waDjXAWM90N"
      },
      "outputs": [],
      "source": [
        "class NetWrapper(torch.nn.Module):\n",
        "  def __init__(self, net):\n",
        "    super().__init__()\n",
        "    self.net = net\n",
        "    self.projector = MLP()\n",
        "    self.activation = {}\n",
        "    self.hook_registered = False\n",
        "\n",
        "  def _register_hook(self):\n",
        "    self.net.layer4.register_forward_hook(self._get_activation('h'))\n",
        "\n",
        "  def _get_activation(self, name):\n",
        "    def hook(model, input, output):\n",
        "        self.activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "  def get_representation(self, inputs):\n",
        "    if not self.hook_registered:\n",
        "      self._register_hook()\n",
        "    _ = self.net(inputs)\n",
        "    return self.activation['h']\n",
        "\n",
        "  def get_masks(self, inputs):\n",
        "    features = self.get_representation(inputs)\n",
        "\n",
        "    masks = []\n",
        "\n",
        "    for feature in features:\n",
        "\n",
        "      num_channels, num_x, num_y = feature.shape\n",
        "      normalized_feature = feature.reshape(num_channels, num_x * num_y)\n",
        "      normalized_feature = normalized_feature.T.cpu()\n",
        "      nn.functional.normalize(normalized_feature, p = 2, dim = 1)\n",
        "\n",
        "      kmeans = KMeans(\n",
        "        init=\"random\",\n",
        "        n_clusters=2,\n",
        "        n_init=10,\n",
        "        max_iter=1000,\n",
        "        random_state=42)\n",
        "    \n",
        "      labels = kmeans.fit_predict(normalized_feature)\n",
        "      labels = labels.reshape(1, num_x, num_y)\n",
        "\n",
        "      # Extend the mask to the original size of the image, so that we can feed\n",
        "      # both the image and the mask through the image augmentation pipeline.\n",
        "      # This is necessary such that both the image and the mask are augmented\n",
        "      # in the exact same way (due to the inherent randomness of augmentation).\n",
        "      labels = nn.functional.interpolate(torch.FloatTensor(labels).unsqueeze(0),\n",
        "                                    size=(image_size, image_size), mode=\"nearest\")[0]\n",
        "\n",
        "      expanded_mask = torch.FloatTensor(labels).repeat(inputs[0].shape[0], 1, 1).to(device)\n",
        "\n",
        "      masks.append(expanded_mask)\n",
        "\n",
        "    masks = torch.stack(masks)\n",
        "    return masks\n",
        "      \n",
        "\n",
        "  def forward(self, inputs, masks_obj1, masks_obj2):\n",
        "    features = self.get_representation(inputs)\n",
        "\n",
        "    mask_pooled_features_obj1 = []\n",
        "    mask_pooled_features_obj2 = []\n",
        "\n",
        "    for idx, feature in enumerate(features):\n",
        "      num_channels, num_x, num_y = feature.shape\n",
        "      feature = feature.reshape(num_channels, num_x * num_y)\n",
        "\n",
        "      # The mask was previously resized to the initial size of images so that\n",
        "      # it can be fed to the augmentation pipeline. Now, we want to apply the\n",
        "      # masks to the feature output by the network, so we have to resize the \n",
        "      # masks to their original sizes in order to be able to apply them.\n",
        "      resized_mask_obj1 = nn.functional.interpolate(masks_obj1[idx][0].unsqueeze(0).unsqueeze(0),\n",
        "                                    size=(num_x, num_y), mode=\"nearest\")[0]\n",
        "      resized_mask_obj2 = nn.functional.interpolate(masks_obj2[idx][0].unsqueeze(0).unsqueeze(0),\n",
        "                                    size=(num_x, num_y), mode=\"nearest\")[0]\n",
        "\n",
        "\n",
        "      resized_mask_obj1 = resized_mask_obj1.repeat(num_channels, 1, 1)\n",
        "      resized_mask_obj2 = resized_mask_obj2.repeat(num_channels, 1, 1)\n",
        "\n",
        "      resized_mask_obj1 = resized_mask_obj1.reshape(num_channels, num_x * num_y)\n",
        "      resized_mask_obj2 = resized_mask_obj2.reshape(num_channels, num_x * num_y)\n",
        "\n",
        "      mask_pooled_feature_obj1 = torch.mean(torch.mul(feature, resized_mask_obj1), dim=(1))\n",
        "      mask_pooled_feature_obj2 = torch.mean(torch.mul(feature, resized_mask_obj2), dim=(1))\n",
        "\n",
        "      mask_pooled_features_obj1.append(mask_pooled_feature_obj1)\n",
        "      mask_pooled_features_obj2.append(mask_pooled_feature_obj2)\n",
        "\n",
        "    mask_pooled_features_obj1 = torch.stack(mask_pooled_features_obj1)\n",
        "    mask_pooled_features_obj2 = torch.stack(mask_pooled_features_obj2)\n",
        "\n",
        "    return self.projector(mask_pooled_features_obj1), self.projector(mask_pooled_features_obj2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlYXx-Cg5VmB"
      },
      "source": [
        "## The Odin architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6ZpXFrp5XCT"
      },
      "outputs": [],
      "source": [
        "def loss_fn(pred_obj1, z_csi_obj1, z_csi_obj2):\n",
        "    pred_obj1 = F.normalize(pred_obj1, dim=-1, p=2)\n",
        "    z_csi_obj1 = F.normalize(z_csi_obj1, dim=-1, p=2)\n",
        "    z_csi_obj2 = F.normalize(z_csi_obj2, dim=-1, p=2)\n",
        "    similar_instances = (pred_obj1 * z_csi_obj1).sum(dim=-1)\n",
        "    dissimilar_instances = (pred_obj1 * z_csi_obj2).sum(dim=-1)\n",
        "\n",
        "    return -torch.log(torch.exp(similar_instances) / torch.exp(similar_instances + dissimilar_instances))\n",
        "\n",
        "class Odin(torch.nn.Module):\n",
        "  def __init__(self, net, moving_average_decay = 0.99):\n",
        "    super().__init__()\n",
        "\n",
        "    DEFAULT_AUG = torch.nn.Sequential(\n",
        "            RandomApply(\n",
        "                pth_transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
        "                p = 0.3\n",
        "            ),\n",
        "            pth_transforms.RandomGrayscale(p=0.2),\n",
        "            pth_transforms.RandomHorizontalFlip(),\n",
        "            RandomApply(\n",
        "                pth_transforms.GaussianBlur((3, 3), (1.0, 2.0)),\n",
        "                p = 0.2\n",
        "            ),\n",
        "            pth_transforms.RandomResizedCrop((image_size, image_size)),\n",
        "            pth_transforms.Normalize(\n",
        "                mean=torch.tensor([0.485, 0.456, 0.406]),\n",
        "                std=torch.tensor([0.229, 0.224, 0.225])),\n",
        "        )\n",
        "    \n",
        "    self.augment1 = DEFAULT_AUG\n",
        "    self.augment2 = DEFAULT_AUG\n",
        "\n",
        "    self.theta_encoder = NetWrapper(net)\n",
        "    self.theta_predictor = MLP(256, 256, 4096).to(device)\n",
        "\n",
        "    self.tau_encoder = deepcopy(self.theta_encoder).to(device)\n",
        "    set_requires_grad(self.tau_encoder, False)\n",
        "\n",
        "    self.csi_encoder = deepcopy(self.theta_encoder).to(device)\n",
        "    set_requires_grad(self.csi_encoder, False)\n",
        "\n",
        "    self.theta_encoder = self.theta_encoder.to(device)\n",
        "\n",
        "    self.target_ema_updater = EMA(moving_average_decay)\n",
        "\n",
        "  def update_moving_average(self):\n",
        "    assert self.tau_encoder is not None, 'target encoder has not been created yet'\n",
        "    assert self.csi_encoder is not None, 'target encoder has not been created yet'\n",
        "\n",
        "    update_moving_average(self.target_ema_updater, self.tau_encoder, self.theta_encoder)\n",
        "    update_moving_average(self.target_ema_updater, self.csi_encoder, self.theta_encoder)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    tau_encoder_masks = self.tau_encoder.get_masks(x)\n",
        "\n",
        "    view_masks_one = self.augment1(torch.concat([x, tau_encoder_masks]))\n",
        "    view_masks_two = self.augment2(torch.concat([x, tau_encoder_masks]))\n",
        "\n",
        "    view_one = view_masks_one[0: len(x)]\n",
        "    view_one_masks = view_masks_one[len(x):]\n",
        "\n",
        "    view_two = view_masks_two[0: len(x)]\n",
        "    view_two_masks = view_masks_two[len(x):]\n",
        "\n",
        "    z_theta_obj1_view1, z_theta_obj2_view1 = self.theta_encoder(view_one, view_one_masks, 1 - view_one_masks)\n",
        "    pred_obj1_view1 = self.theta_predictor(z_theta_obj1_view1)\n",
        "    pred_obj2_view1 = self.theta_predictor(z_theta_obj2_view1)\n",
        "\n",
        "    z_theta_obj1_view2, z_theta_obj2_view2 = self.theta_encoder(view_two, view_two_masks, 1 - view_two_masks)\n",
        "    pred_obj1_view2 = self.theta_predictor(z_theta_obj1_view1)\n",
        "    pred_obj2_view2 = self.theta_predictor(z_theta_obj2_view1)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      z_csi_obj1_view2, z_csi_obj2_view2 = self.csi_encoder(view_two, view_two_masks, 1 - view_two_masks)\n",
        "      z_csi_obj1_view1, z_csi_obj2_view1 = self.csi_encoder(view_one, view_one_masks, 1 - view_one_masks)\n",
        "\n",
        "    # Every instance in the batch from pred_obj1 must be similar to z_csi_obj1 (same obj, diff. views, same img).\n",
        "    # But each one must be different from z_csi_obj2 (diff. object, diff. views, same image).\n",
        "    # Bacause the theta and csi encoders are different, we have to repeat the same steps for z_csi_obj1\n",
        "    #  from the second view too.\n",
        "    # Additionally, the same procedure must be done for pred_obj2 as well.\n",
        "\n",
        "    loss_obj1 = (loss_fn(pred_obj1_view1, z_csi_obj1_view2, z_csi_obj2_view2) + \\\n",
        "                loss_fn(pred_obj1_view2, z_csi_obj1_view1, z_csi_obj2_view1)) / 2\n",
        "    loss_obj2 = (loss_fn(pred_obj2_view1, z_csi_obj2_view2, z_csi_obj1_view2) + \\\n",
        "                loss_fn(pred_obj2_view2, z_csi_obj2_view1, z_csi_obj1_view1)) / 2\n",
        "\n",
        "    return (loss_obj1 + loss_obj2).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJG8aWti0FKm"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHOPwnIpCNVK"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import torchvision\n",
        "\n",
        "def process_input(image):\n",
        "  # patch_size = 16\n",
        "\n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    # transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "  input_tensor = preprocess(image)\n",
        "\n",
        "  input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "  input_batch = input_batch\n",
        "\n",
        "  return input_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPy6CY1jPB4h",
        "outputId": "5ab9f574-9120-478d-d67d-f856e95c5970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "img1 = Image.open('data/apple1.jpg')\n",
        "img1 = img1.convert('RGB')\n",
        "\n",
        "img2 = Image.open('data/apple2.jpg')\n",
        "img2 = img2.convert('RGB')\n",
        "\n",
        "# img = Image.open(filename)\n",
        "\n",
        "input1 = process_input(img1)\n",
        "input2 = process_input(img2)\n",
        "\n",
        "inputs = torch.stack([input1.squeeze(0), input2.squeeze(0)])\n",
        "print(inputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3opXy_lV9BVA"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "\n",
        "for filename in sorted(os.listdir('data')):\n",
        "  img = Image.open(os.path.join('data', filename))\n",
        "  img = img.convert('RGB')\n",
        "\n",
        "  img = process_input(img).squeeze(0)\n",
        "\n",
        "  dataset.append(img)\n",
        "\n",
        "dataset = torch.stack(dataset)\n",
        "\n",
        "dataset_labels = []\n",
        "\n",
        "for filename in sorted(os.listdir('labels')):\n",
        "  img = Image.open(os.path.join('labels', filename))\n",
        "  img = img.convert('RGB')\n",
        "\n",
        "  img = process_input(img).squeeze(0)\n",
        "\n",
        "  dataset_labels.append(img)\n",
        "\n",
        "dataset_labels = torch.stack(dataset_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb2vrrznyGV-"
      },
      "source": [
        "# Odin trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoY7O4fKyFy4",
        "outputId": "2ab57061-24a1-4b7d-bf01-9483238889e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[K     |████████████████████████████████| 708 kB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.8.2)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.9.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.49.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.1)\n",
            "Installing collected packages: torchmetrics, pyDeprecate, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.7.7 torchmetrics-0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning\n",
        "import pytorch_lightning as pl\n",
        "import multiprocessing\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "BATCH_SIZE = 12\n",
        "EPOCHS     = 60\n",
        "LR         = 3e-4\n",
        "NUM_GPUS   = 1\n",
        "NUM_WORKERS = multiprocessing.cpu_count()\n",
        "\n",
        "class SelfSupervisedLearner(pl.LightningModule):\n",
        "    def __init__(self, net, **kwargs):\n",
        "        super().__init__()\n",
        "        self.learner = Odin(net)\n",
        "\n",
        "    def forward(self, images):\n",
        "        return self.learner(images)\n",
        "\n",
        "    def training_step(self, images, _):\n",
        "        loss = self.forward(images)\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=LR)\n",
        "\n",
        "    def on_before_zero_grad(self, _):\n",
        "        self.learner.update_moving_average()\n",
        "\n",
        "train_loader = DataLoader(dataset.to(device), batch_size=BATCH_SIZE, shuffle=True)\n",
        "# model = model.to(device)\n",
        "model.train()\n",
        "odin_model = SelfSupervisedLearner(model)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs = EPOCHS,\n",
        "    gpus = NUM_GPUS,\n",
        "    accumulate_grad_batches = 1,\n",
        "    sync_batchnorm = True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(odin_model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "05488809f7bc4e519580943869828861",
            "b5109818eced443dac7573a930447467",
            "f47b59ab7a6d41b08b3b975c7a35e925",
            "6c5c5594b72346ea9173a03eb59c987f",
            "18f166a9a1634f9097b86e0224070cab",
            "94096418162b4272b204b3a0fa4709dd",
            "bf4800bba3a84dafabd4182278261815",
            "a3a3e7faaa164e6a990a8ff2bd26dca0",
            "ff0cdbd2f1b84c3ab874f86592a28d7b",
            "cfe7a236ed644404aad97dd19644b258",
            "299a594c48954e918c89043842bc5cc5"
          ]
        },
        "id": "501ZvxBZaVLO",
        "outputId": "564b7729-549b-44c8-bb52-a50cf846c0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type | Params\n",
            "---------------------------------\n",
            "0 | learner | Odin | 46.7 M\n",
            "---------------------------------\n",
            "17.0 M    Trainable params\n",
            "29.7 M    Non-trainable params\n",
            "46.7 M    Total params\n",
            "186.612   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05488809f7bc4e519580943869828861"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and load.\n",
        "Save only the online encoder."
      ],
      "metadata": {
        "id": "1iacn3Oyw2-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(odin_model.learner.theta_encoder.state_dict(), \"model.pt\")"
      ],
      "metadata": {
        "id": "jZ5J2QnBwr1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odin_model.learner.theta_encoder.load_state_dict(torch.load(\"odin_kmeans_res512_60epochs_co3d.pt\"))\n",
        "odin_model.learner.theta_encoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Kbf9sjU7wvaZ",
        "outputId": "15ab1719-6e64-4a46-d422-3f3fca29d38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6662d9d9f957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0modin_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"odin_kmeans_res512_60epochs_co3d.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0modin_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'odin_kmeans_res512_60epochs_co3d.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrUISFJwzQga"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "762zxVPKIzK2"
      },
      "outputs": [],
      "source": [
        "odin_model.learner.theta_encoder = odin_model.learner.theta_encoder.to(device)\n",
        "odin_model.learner.theta_encoder.eval()\n",
        "masks = odin_model.learner.theta_encoder.get_masks(inputs[0].unsqueeze(0).to(device)).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(masks.shape)"
      ],
      "metadata": {
        "id": "zQr-iHih-5eC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c66443a-2b1e-495c-b7bb-c30438a85c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wPALbMxzFa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a2304eb7-056a-4410-b628-75e892c1ced4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3758660850>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(masks[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.transpose(dataset_labels[0], axes=(1, 2, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "j2aJHURom_0S",
        "outputId": "f5d6e86e-ac17-4dfc-d029-ce16f0f716af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f36a1a3cf50>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6uTLKeg5TaT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "computed_masks = []\n",
        "\n",
        "for input_data in dataset:\n",
        "  masks = odin_model.learner.theta_encoder.get_masks(input_data.unsqueeze(0).to(device)).cpu()\n",
        "\n",
        "  labels = masks[0][0].cpu().numpy()\n",
        "\n",
        "  labels[labels < 0] = 0\n",
        "  labels[labels > 0] = 1\n",
        "\n",
        "  # Revert the mask if \"1\"s denote the background instead of the main object.\n",
        "  if len(labels[labels == 1]) > len(labels[labels == 0]):\n",
        "    labels = 1 - labels\n",
        "\n",
        "  computed_masks.append(labels)\n",
        "\n",
        "computed_masks = np.array(computed_masks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(computed_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "dExhBOILqaby",
        "outputId": "e8168519-b627-450d-c637-282f6f7341cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f374c2f2b90>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iou = []\n",
        "for idx, dataset_label in enumerate(dataset_labels):\n",
        "  if idx < 20:\n",
        "    # Use only the first channel, since they are similar.\n",
        "    dataset_label[0][dataset_label[0] < 0] = 0\n",
        "    dataset_label[0][dataset_label[0] > 0] = 1\n",
        "\n",
        "    dataset_label = dataset_label[0].cpu().numpy()\n",
        "\n",
        "    intersection = (np.logical_and(dataset_label, computed_masks[idx])).sum()\n",
        "    union = (np.logical_or(dataset_label, computed_masks[idx])).sum()\n",
        "    iou.append(intersection / union)\n",
        "print(iou)\n",
        "print(iou[10])\n",
        "print(np.sum(iou) / len(iou))"
      ],
      "metadata": {
        "id": "h7SyhAuh_Xpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56957c2a-c236-4227-b032-1a708700a637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5975518173625713, 0.600675929402929, 0.493408203125, 0.49285888671875, 0.49505615234375, 0.49639892578125, 0.6017548571940191, 0.6407130367204197, 0.6044936316366932, 0.6109101160550674, 0.5887456037514655, 0.4779385653409091, 0.587945679813883, 0.5832975756275477, 0.510317876376114, 0.5314973385790326, 0.5280229479258606, 0.541600283235971, 0.5413203149052206, 0.49927737197765715]\n",
            "0.5887456037514655\n",
            "0.5511892556937055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4ZpGCrjcN0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCKhpWsYurCUi6+gCSGErQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56f577905d3344589cc33ff9be673bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b7c07e61dc14a33a9a627c6032b4f1f",
              "IPY_MODEL_c7c575f7a25e4c64a87457b1f4c7c91d",
              "IPY_MODEL_f586e5a2277b4e3498290f83cb993a7f"
            ],
            "layout": "IPY_MODEL_bc453cbeee774494aeb4db37a760351e"
          }
        },
        "7b7c07e61dc14a33a9a627c6032b4f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e751e59fc5478e883ccadf01347031",
            "placeholder": "​",
            "style": "IPY_MODEL_0a86c7861db4449980fd1779593ad4a6",
            "value": "100%"
          }
        },
        "c7c575f7a25e4c64a87457b1f4c7c91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd7b79344a444d7995d665f63f506a5",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6499f411fc847b6966bda351a4281f5",
            "value": 46830571
          }
        },
        "f586e5a2277b4e3498290f83cb993a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b9d4f167a04795ae09706add1080b2",
            "placeholder": "​",
            "style": "IPY_MODEL_7169c9b31a84472aa33fe8a936d3216a",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 40.9MB/s]"
          }
        },
        "bc453cbeee774494aeb4db37a760351e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e751e59fc5478e883ccadf01347031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a86c7861db4449980fd1779593ad4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcd7b79344a444d7995d665f63f506a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6499f411fc847b6966bda351a4281f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0b9d4f167a04795ae09706add1080b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7169c9b31a84472aa33fe8a936d3216a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05488809f7bc4e519580943869828861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5109818eced443dac7573a930447467",
              "IPY_MODEL_f47b59ab7a6d41b08b3b975c7a35e925",
              "IPY_MODEL_6c5c5594b72346ea9173a03eb59c987f"
            ],
            "layout": "IPY_MODEL_18f166a9a1634f9097b86e0224070cab"
          }
        },
        "b5109818eced443dac7573a930447467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94096418162b4272b204b3a0fa4709dd",
            "placeholder": "​",
            "style": "IPY_MODEL_bf4800bba3a84dafabd4182278261815",
            "value": "Epoch 59: 100%"
          }
        },
        "f47b59ab7a6d41b08b3b975c7a35e925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3a3e7faaa164e6a990a8ff2bd26dca0",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff0cdbd2f1b84c3ab874f86592a28d7b",
            "value": 21
          }
        },
        "6c5c5594b72346ea9173a03eb59c987f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe7a236ed644404aad97dd19644b258",
            "placeholder": "​",
            "style": "IPY_MODEL_299a594c48954e918c89043842bc5cc5",
            "value": " 21/21 [00:06&lt;00:00,  3.08it/s, loss=-1.69, v_num=0]"
          }
        },
        "18f166a9a1634f9097b86e0224070cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "94096418162b4272b204b3a0fa4709dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4800bba3a84dafabd4182278261815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3a3e7faaa164e6a990a8ff2bd26dca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0cdbd2f1b84c3ab874f86592a28d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfe7a236ed644404aad97dd19644b258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299a594c48954e918c89043842bc5cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}