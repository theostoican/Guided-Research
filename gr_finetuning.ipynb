{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmxDVbzwwUeTbuo2y6ZsnK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theostoican/Guided-Research/blob/main/gr_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A463KKCgOCVk",
        "outputId": "3fa01d7b-5e9a-41e6-fd7b-38bbaa8ff7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 18.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (5.0.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        }
      ],
      "source": [
        "!pip install timm \n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "vitb16 = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "# summary(vitb16, (1, 3, 224, 224))\n",
        "vitb16.blocks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_IMxT-cQYxE",
        "outputId": "23a8bee9-5094-4c87-be7e-69e6a2b77707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (1): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (2): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (3): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (4): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (5): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (6): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (7): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (8): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (9): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (10): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (11): Block(\n",
              "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (attn): Attention(\n",
              "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (drop_path): Identity()\n",
              "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (mlp): Mlp(\n",
              "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate=none)\n",
              "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vitb16.parameters():\n",
        "  param.required_grad = True\n"
      ],
      "metadata": {
        "id": "WLaLl0BQjSHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import ViTFeatureExtractor\n",
        "from PIL import Image\n",
        "from torchvision import transforms as pth_transforms\n",
        "import os\n",
        "import torchvision\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('facebook/dino-vitb16')\n",
        "\n",
        "def process_input(image):\n",
        "  patch_size = 16\n",
        "\n",
        "  transform = pth_transforms.Compose([\n",
        "          pth_transforms.Resize((480, 480)),\n",
        "          pth_transforms.ToTensor(),\n",
        "          pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "      ])\n",
        "  image = transform(image)\n",
        "\n",
        "  w, h = image.shape[1] - image.shape[1] % patch_size, image.shape[2] - image.shape[2] % patch_size\n",
        "  image = image[:, :w, :h].unsqueeze(0).to(device)\n",
        "\n",
        "  return image\n",
        "\n",
        "def process_output(image):\n",
        "\n",
        "  transform = pth_transforms.Compose([\n",
        "          pth_transforms.Resize((901, 901)),\n",
        "          pth_transforms.ToTensor(),\n",
        "      ])\n",
        "  image = transform(image).to(device)\n",
        "\n",
        "  return image\n",
        "\n",
        "inputs = []\n",
        "labels = []\n",
        "\n",
        "for img_name in sorted(os.listdir(os.path.join('data', 'data'))):\n",
        "  img = Image.open(os.path.join('data', 'data', img_name))\n",
        "  input = process_input(img)\n",
        "  inputs.append(input)\n",
        "\n",
        "for img_name in sorted(os.listdir(os.path.join('data', 'labels'))):\n",
        "  img = Image.open(os.path.join('data', 'labels', img_name))\n",
        "  segmentation_map = process_output(img)\n",
        "  labels.append(segmentation_map)\n",
        "\n",
        "inputs = torch.stack(inputs).to(device)\n",
        "labels = torch.stack(labels).to(device)\n",
        "\n",
        "dataset = [(input, label) for (input, label) in zip(inputs, labels)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CLNA8Izb0-y",
        "outputId": "2797ad9b-8669-4241-b6c2-2b2027d4ba66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "plt.imshow(F.to_pil_image(labels[50].detach()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "0MVE9G1QvwMy",
        "outputId": "c5424c48-6477-477f-dcaa-07a1865fdd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f62255f09d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = vitb16(inputs[0])\n",
        "vitb16.get_last_selfattention(inputs[0].to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw9GeQZG25xU",
        "outputId": "4939eaa5-a14b-46a7-a07b-29fa27f16f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12, 901, 901])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_attentions(inputs, attentions):\n",
        "  attentions = attentions.detach()\n",
        "\n",
        "  nh = attentions.shape[1] # number of heads\n",
        "\n",
        "\n",
        "  patch_size = 16\n",
        "  w, h = inputs.shape[-2] - inputs.shape[-2] % patch_size, inputs.shape[-1] - inputs.shape[-1] % patch_size\n",
        "  inputs = inputs[:, :w, :h].unsqueeze(0)\n",
        "\n",
        "  w_featmap = inputs.shape[-2] // patch_size\n",
        "  h_featmap = inputs.shape[-1] // patch_size\n",
        "\n",
        "  attentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n",
        "\n",
        "  attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
        "  attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=patch_size, mode=\"nearest\")[0].cpu().numpy()\n",
        "\n",
        "  print(attentions.shape)\n",
        "\n",
        "  # save attentions heatmaps\n",
        "  os.makedirs('maps', exist_ok=True)\n",
        "  torchvision.utils.save_image(torchvision.utils.make_grid(inputs, normalize=True, scale_each=True),\n",
        "                              os.path.join('maps', \"img.png\"))\n",
        "  for j in range(nh):\n",
        "      fname = os.path.join('maps', \"attn-head\" + str(j) + \".png\")\n",
        "      plt.imsave(fname=fname, arr=attentions[j], format='png')\n",
        "      print(f\"{fname} saved.\")\n",
        "\n",
        "save_attentions(inputs[0], vitb16.get_last_selfattention(inputs[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3E8-QO8B763",
        "outputId": "d2cea743-2f3e-415b-de38-0b73d47510bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 480, 480)\n",
            "maps/attn-head0.png saved.\n",
            "maps/attn-head1.png saved.\n",
            "maps/attn-head2.png saved.\n",
            "maps/attn-head3.png saved.\n",
            "maps/attn-head4.png saved.\n",
            "maps/attn-head5.png saved.\n",
            "maps/attn-head6.png saved.\n",
            "maps/attn-head7.png saved.\n",
            "maps/attn-head8.png saved.\n",
            "maps/attn-head9.png saved.\n",
            "maps/attn-head10.png saved.\n",
            "maps/attn-head11.png saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def my_loss(attentions, target):\n",
        "  inverted_target = 1 - target\n",
        "  loss = torch.mean((torch.mul(target, attentions[0]) - \\\n",
        "                     torch.mul(inverted_target, attentions[1])) ** 2) + \\\n",
        "         torch.mean((torch.mul(inverted_target, attentions[0]) - \\\n",
        "                     torch.mul(target, attentions[1])) ** 2)\n",
        "  return loss\n",
        "\n",
        "def train(model, inputs, labels, max_epochs = 100):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    loss_avg = 0\n",
        "    for (input, label) in zip(inputs, labels):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = vitb16(input)\n",
        "      attentions = vitb16.get_last_selfattention(input.to(device))[0]\n",
        "\n",
        "      loss = my_loss(attentions, label)\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_avg += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch}, average loss: {loss_avg / len(dataset)}')\n"
      ],
      "metadata": {
        "id": "8vd1pJ0KjZwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels.shape)\n",
        "train(vitb16, inputs, labels[:, 0, :, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyb9dbwWPkwJ",
        "outputId": "88819526-724c-43fa-ec51-dd29fdf41e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([245, 1, 901, 901])\n",
            "Epoch 0, average loss: 2.3993750281598685e-06\n",
            "Epoch 1, average loss: 2.399344330857572e-06\n",
            "Epoch 2, average loss: 2.3993048773486314e-06\n",
            "Epoch 3, average loss: 2.3992655027244356e-06\n",
            "Epoch 4, average loss: 2.399228620858167e-06\n",
            "Epoch 5, average loss: 2.3991950818489554e-06\n",
            "Epoch 6, average loss: 2.3991711417210707e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_attentions(dataset[50][0], vitb16.get_last_selfattention(dataset[50][0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI-HcRkQqeww",
        "outputId": "6be52c9b-f417-40df-fb93-85959f20894b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 480, 480)\n",
            "maps/attn-head0.png saved.\n",
            "maps/attn-head1.png saved.\n",
            "maps/attn-head2.png saved.\n",
            "maps/attn-head3.png saved.\n",
            "maps/attn-head4.png saved.\n",
            "maps/attn-head5.png saved.\n",
            "maps/attn-head6.png saved.\n",
            "maps/attn-head7.png saved.\n",
            "maps/attn-head8.png saved.\n",
            "maps/attn-head9.png saved.\n",
            "maps/attn-head10.png saved.\n",
            "maps/attn-head11.png saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdAEG9Xxuruw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}